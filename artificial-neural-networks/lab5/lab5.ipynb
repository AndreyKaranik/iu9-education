{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD - Epoch 1 loss: 0.34208737964531394\n",
      "SGD - Epoch 2 loss: 0.06708169150660669\n",
      "SGD - Epoch 3 loss: 0.0486749055710232\n",
      "SGD - Epoch 4 loss: 0.038134266142554676\n",
      "SGD - Epoch 5 loss: 0.031376708751737474\n",
      "SGD - Epoch 6 loss: 0.02522663792545561\n",
      "SGD - Epoch 7 loss: 0.022186635151225105\n",
      "SGD - Epoch 8 loss: 0.020125792791232538\n",
      "SGD - Epoch 9 loss: 0.016503351816405283\n",
      "SGD - Epoch 10 loss: 0.014967438391228799\n",
      "SGD - Accuracy: 98.9%\n",
      "AdaDelta - Epoch 1 loss: 0.013803958114899838\n",
      "AdaDelta - Epoch 2 loss: 0.013791049800976465\n",
      "AdaDelta - Epoch 3 loss: 0.013800779677913795\n",
      "AdaDelta - Epoch 4 loss: 0.013791054872408125\n",
      "AdaDelta - Epoch 5 loss: 0.01379089171144387\n",
      "AdaDelta - Epoch 6 loss: 0.013792666369519759\n",
      "AdaDelta - Epoch 7 loss: 0.013794483030419066\n",
      "AdaDelta - Epoch 8 loss: 0.013793351786364844\n",
      "AdaDelta - Epoch 9 loss: 0.013793166985531354\n",
      "AdaDelta - Epoch 10 loss: 0.013799228076173028\n",
      "AdaDelta - Accuracy: 98.9%\n",
      "NAG - Epoch 1 loss: 0.013849211322265737\n",
      "NAG - Epoch 2 loss: 0.013785286670654212\n",
      "NAG - Epoch 3 loss: 0.013747812568481928\n",
      "NAG - Epoch 4 loss: 0.0137258226457984\n",
      "NAG - Epoch 5 loss: 0.013707539660929182\n",
      "NAG - Epoch 6 loss: 0.013691721514545733\n",
      "NAG - Epoch 7 loss: 0.013670635639652567\n",
      "NAG - Epoch 8 loss: 0.013651853319727169\n",
      "NAG - Epoch 9 loss: 0.013635604939548263\n",
      "NAG - Epoch 10 loss: 0.013624542548794838\n",
      "NAG - Accuracy: 98.9%\n",
      "Adam - Epoch 1 loss: 0.013441725855419931\n",
      "Adam - Epoch 2 loss: 0.01312803605028547\n",
      "Adam - Epoch 3 loss: 0.012874758364458816\n",
      "Adam - Epoch 4 loss: 0.01254808328754106\n",
      "Adam - Epoch 5 loss: 0.012283747130122973\n",
      "Adam - Epoch 6 loss: 0.012029307662454587\n",
      "Adam - Epoch 7 loss: 0.01177779106195951\n",
      "Adam - Epoch 8 loss: 0.011546670466808741\n",
      "Adam - Epoch 9 loss: 0.01132561801537151\n",
      "Adam - Epoch 10 loss: 0.011112679179388466\n",
      "Adam - Accuracy: 98.92%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as fctl\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fctl.relu(self.conv1(x))\n",
    "        x = fctl.max_pool2d(x, 2)\n",
    "        x = fctl.relu(self.conv2(x))\n",
    "        x = fctl.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = fctl.relu(self.fc1(x))\n",
    "        x = fctl.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = LeNet()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_adadelta = optim.Adadelta(model.parameters(), lr=0.0000001)\n",
    "optimizer_nag = optim.SGD(model.parameters(), lr=0.0000001, momentum=0.9, nesterov=True)\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=0.0000001)\n",
    "\n",
    "def train_test_model(optimizer, name):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        losses.append(epoch_loss)\n",
    "        print(f\"{name} - Epoch {epoch + 1} loss: {epoch_loss}\")\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{name} - Accuracy: {accuracy}%\")\n",
    "\n",
    "    return losses\n",
    "\n",
    "sgd_losses = train_test_model(optimizer_sgd, \"SGD\")\n",
    "adadelta_losses = train_test_model(optimizer_adadelta, \"AdaDelta\")\n",
    "nag_losses = train_test_model(optimizer_nag, \"NAG\")\n",
    "adam_losses = train_test_model(optimizer_adam, \"Adam\")\n",
    "\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, sgd_losses, label='SGD')\n",
    "plt.plot(epochs, adadelta_losses, label='AdaDelta')\n",
    "plt.plot(epochs, nag_losses, label='NAG')\n",
    "plt.plot(epochs, adam_losses, label='Adam')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss function dependence on the number of epochs for each optimizer')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     43\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 44\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     48\u001b[0m optimizer_losses[epoch] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\sgd.py:123\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    117\u001b[0m momentum_buffer_list: List[Optional[Tensor]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    119\u001b[0m has_sparse_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    120\u001b[0m     group, params, grads, momentum_buffer_list\n\u001b[0;32m    121\u001b[0m )\n\u001b[1;32m--> 123\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdampening\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnesterov\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params, momentum_buffer_list):\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\sgd.py:298\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[1;32m--> 298\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\sgd.py:344\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[1;34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[0;32m    342\u001b[0m     momentum_buffer_list[i] \u001b[38;5;241m=\u001b[39m buf\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m     \u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dampening)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov:\n\u001b[0;32m    347\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(buf, alpha\u001b[38;5;241m=\u001b[39mmomentum)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vgg16(pretrained=False)\n",
    "num_classes = 10\n",
    "model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "optimizers = {\n",
    "    \"SGD\": optim.SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "    \"AdaDelta\": optim.Adadelta(model.parameters(), lr=0.01),\n",
    "    \"NAG\": optim.SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True),\n",
    "    \"Adam\": optim.Adam(model.parameters(), lr=0.00001)\n",
    "}\n",
    "\n",
    "for optimizer_name, optimizer in optimizers.items():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epochs = 5\n",
    "\n",
    "    optimizer_losses = [0] * epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            optimizer_losses[epoch] += loss.item()\n",
    "\n",
    "        optimizer_losses[epoch] /= len(trainloader)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy of the network with {optimizer_name} optimizer: {100 * correct / total}%\")\n",
    "\n",
    "    plt.plot(range(1, epochs + 1), optimizer_losses, label=optimizer_name)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss function dependence on the number of epochs for optimizer ' + optimizer_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     57\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 58\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     60\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m--> 276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\resnet.py:92\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     90\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m---> 92\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model = models.resnet34(pretrained=False)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "accuracies = {}\n",
    "optimizers = ['SGD', 'Adadelta', 'NAG', 'Adam']\n",
    "losses = {optimizer_name: [] for optimizer_name in optimizers}\n",
    "\n",
    "for optimizer_name in optimizers:\n",
    "    if optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    elif optimizer_name == 'Adadelta':\n",
    "        optimizer = optim.Adadelta(model.parameters())\n",
    "    elif optimizer_name == 'NAG':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "    elif optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Optimizer: {optimizer_name}, Loss: {running_loss / len(train_loader)}\")\n",
    "        losses[optimizer_name].append(running_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    accuracies[optimizer_name] = accuracy\n",
    "    print(f'Accuracy of the network on the test images with {optimizer_name} optimizer: {accuracy:.2f}%')\n",
    "    plt.plot(range(1, 6), losses[optimizer_name], label=optimizer_name)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss function dependence on the number of epochs for optimizer ' + optimizer_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Accuracies for different optimizers:\")\n",
    "for optimizer_name, accuracy in accuracies.items():\n",
    "    print(f\"{optimizer_name}: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
